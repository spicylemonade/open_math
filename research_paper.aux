\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{applegate2006traveling}
\citation{applegate2006traveling}
\citation{helsgaun2000effective,helsgaun2009general,helsgaun2017extension}
\citation{cook2025korea}
\citation{kool2019attention,kwon2020pomo}
\citation{xin2021neurolkh,zheng2021vsrlkh}
\citation{pan2023htsp}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1}{}}
\citation{helsgaun2000effective}
\citation{helsgaun2009general}
\citation{helsgaun2017extension}
\citation{perron2023ortools}
\citation{coupey2018vroom}
\citation{kool2019attention}
\citation{kwon2020pomo}
\citation{pan2023htsp}
\citation{pan2025dualopt}
\citation{xin2021neurolkh}
\citation{zheng2021vsrlkh,zheng2022reinforced}
\citation{wang2025mabb}
\citation{lischka2024great}
\citation{embedlkh2025}
\citation{liu2025unics}
\@writefile{toc}{\contentsline {paragraph}{Contributions.}{2}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Classical ATSP solvers.}{2}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learned constructive models.}{2}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Learned candidate generation for LKH.}{2}{section*.4}\protected@file@percent }
\citation{luxen2011realtime}
\citation{boeing2017osmnx}
\citation{reinelt1991tsplib}
\citation{ascheuer2001solving}
\@writefile{toc}{\contentsline {paragraph}{Road-network data and tools.}{3}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Problem Formulation}{3}{section.3}\protected@file@percent }
\newlabel{sec:problem}{{3}{3}{Problem Formulation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Asymmetric TSP on Road Networks}{3}{subsection.3.1}\protected@file@percent }
\newlabel{eq:atsp}{{1}{3}{Asymmetric TSP on Road Networks}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Time-Dependent Extension (TD-ATSP)}{3}{subsection.3.2}\protected@file@percent }
\newlabel{eq:td-atsp}{{2}{3}{Time-Dependent Extension (TD-ATSP)}{equation.3.2}{}}
\newlabel{eq:td-cost}{{3}{3}{Time-Dependent Extension (TD-ATSP)}{equation.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Notation}{3}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Research Hypotheses}{3}{subsection.3.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Summary of notation.\relax }}{4}{table.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:notation}{{1}{4}{Summary of notation.\relax }{table.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Overview of the hybrid solver pipeline. The road-network data pipeline generates an asymmetric cost matrix, which feeds both the OR-Tools initialization (lower path) and GNN edge scoring (upper path). Learned candidate sets constrain the local search, and RL-guided moves target expensive edges. A final 2-opt polish step uses remaining time budget.\relax }}{4}{figure.caption.7}\protected@file@percent }
\newlabel{fig:architecture}{{1}{4}{Overview of the hybrid solver pipeline. The road-network data pipeline generates an asymmetric cost matrix, which feeds both the OR-Tools initialization (lower path) and GNN edge scoring (upper path). Learned candidate sets constrain the local search, and RL-guided moves target expensive edges. A final 2-opt polish step uses remaining time budget.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Method}{4}{section.4}\protected@file@percent }
\newlabel{sec:method}{{4}{4}{Method}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Data Pipeline}{4}{subsection.4.1}\protected@file@percent }
\newlabel{sec:data}{{4.1}{4}{Data Pipeline}{subsection.4.1}{}}
\citation{xin2021neurolkh}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces One \textsc  {DirectedEdgeAttention} layer. Query embeddings come from destination nodes, key embeddings from source nodes with edge-feature conditioning, preserving the directed nature of the road graph. A sigmoid gate controls the balance between incoming messages and the node's own state, preventing over-smoothing.\relax }}{5}{figure.caption.11}\protected@file@percent }
\newlabel{fig:gnn_layer}{{2}{5}{One \textsc {DirectedEdgeAttention} layer. Query embeddings come from destination nodes, key embeddings from source nodes with edge-feature conditioning, preserving the directed nature of the road graph. A sigmoid gate controls the balance between incoming messages and the node's own state, preventing over-smoothing.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Directed GNN Edge Scorer}{5}{subsection.4.2}\protected@file@percent }
\newlabel{sec:gnn}{{4.2}{5}{Directed GNN Edge Scorer}{subsection.4.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Input features.}{5}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Graph construction.}{5}{section*.9}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Architecture.}{5}{section*.10}\protected@file@percent }
\newlabel{eq:attention}{{4}{5}{Architecture}{equation.4.4}{}}
\newlabel{eq:gate}{{5}{5}{Architecture}{equation.4.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Training.}{5}{section*.12}\protected@file@percent }
\citation{perron2023ortools}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces GNN training attempts with progressive refinements. The final configuration using focal loss with a smaller $k$-NN graph achieved the best $F_1$ score. While precision remains below target, ranking quality is sufficient for candidate set generation (99.5\% recall at $k{=}10$).\relax }}{6}{table.caption.13}\protected@file@percent }
\newlabel{tab:training}{{2}{6}{GNN training attempts with progressive refinements. The final configuration using focal loss with a smaller $k$-NN graph achieved the best $F_1$ score. While precision remains below target, ranking quality is sufficient for candidate set generation (99.5\% recall at $k{=}10$).\relax }{table.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Learned Candidate Set Generation}{6}{subsection.4.3}\protected@file@percent }
\newlabel{sec:candidates}{{4.3}{6}{Learned Candidate Set Generation}{subsection.4.3}{}}
\newlabel{eq:recall}{{6}{6}{Learned Candidate Set Generation}{equation.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}RL-Guided Local Search}{6}{subsection.4.4}\protected@file@percent }
\newlabel{sec:rl}{{4.4}{6}{RL-Guided Local Search}{subsection.4.4}{}}
\@writefile{toc}{\contentsline {paragraph}{State space.}{6}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Action space.}{6}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reward.}{6}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Training.}{6}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Hybrid Solver Pipeline}{6}{subsection.4.5}\protected@file@percent }
\newlabel{sec:hybrid}{{4.5}{6}{Hybrid Solver Pipeline}{subsection.4.5}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces RL-Guided Local Search\relax }}{7}{algorithm.1}\protected@file@percent }
\newlabel{alg:rl_search}{{1}{7}{RL-Guided Local Search\relax }{algorithm.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Hybrid Solver Pipeline\relax }}{7}{algorithm.2}\protected@file@percent }
\newlabel{alg:hybrid}{{2}{7}{Hybrid Solver Pipeline\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Time-Dependent Traffic Model}{7}{subsection.4.6}\protected@file@percent }
\newlabel{sec:traffic}{{4.6}{7}{Time-Dependent Traffic Model}{subsection.4.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experimental Setup}{7}{section.5}\protected@file@percent }
\newlabel{sec:experiments}{{5}{7}{Experimental Setup}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Benchmark Instances}{7}{subsection.5.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Speed multipliers relative to free-flow speed by road type and time period. Evening peak on arterial roads incurs the largest slowdown (0.40$\times $), creating substantial route-dependent cost variations that static models cannot capture.\relax }}{8}{table.caption.18}\protected@file@percent }
\newlabel{tab:traffic}{{3}{8}{Speed multipliers relative to free-flow speed by road type and time period. Evening peak on arterial roads incurs the largest slowdown (0.40$\times $), creating substantial route-dependent cost variations that static models cannot capture.\relax }{table.caption.18}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Baseline solvers. OR-Tools provides the strongest baseline due to its C++ implementation of guided local search. The LKH-style solver approximates LKH's approach but runs ${\sim }100\times $ slower than the native C implementation.\relax }}{8}{table.caption.19}\protected@file@percent }
\newlabel{tab:baselines}{{4}{8}{Baseline solvers. OR-Tools provides the strongest baseline due to its C++ implementation of guided local search. The LKH-style solver approximates LKH's approach but runs ${\sim }100\times $ slower than the native C implementation.\relax }{table.caption.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Baselines}{8}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Evaluation Protocol}{8}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Hyperparameters}{8}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{8}{section.6}\protected@file@percent }
\newlabel{sec:results}{{6}{8}{Results}{section.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Baseline Performance}{8}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Time-Budget Analysis}{8}{subsection.6.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Key hyperparameters. The GNN uses a compact architecture (${\sim }$150K parameters) suitable for CPU inference. The RL agent's 75-action Q-table enables fast lookup without neural network overhead.\relax }}{9}{table.caption.20}\protected@file@percent }
\newlabel{tab:hyperparams}{{5}{9}{Key hyperparameters. The GNN uses a compact architecture (${\sim }$150K parameters) suitable for CPU inference. The RL agent's 75-action Q-table enables fast lookup without neural network overhead.\relax }{table.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Performance on 200-stop instances at $T{=}30$\,s (mean $\pm $ std across 3 cities $\times $ 3 seeds). The hybrid solver achieves the second-best mean gap (0.20\%), behind only OR-Tools (0.05\%), while substantially outperforming the LKH-style baseline (0.66\%). Bold indicates best result per column.\relax }}{9}{table.caption.21}\protected@file@percent }
\newlabel{tab:baselines_results}{{6}{9}{Performance on 200-stop instances at $T{=}30$\,s (mean $\pm $ std across 3 cities $\times $ 3 seeds). The hybrid solver achieves the second-best mean gap (0.20\%), behind only OR-Tools (0.05\%), while substantially outperforming the LKH-style baseline (0.66\%). Bold indicates best result per column.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Candidate Set Quality}{9}{subsection.6.3}\protected@file@percent }
\newlabel{sec:results_candidates}{{6.3}{9}{Candidate Set Quality}{subsection.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}RL Local Search}{9}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.5}Ablation Study}{9}{subsection.6.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Optimality gap (\%) vs.\ best-known solution on 200-stop instances across time budgets. The hybrid solver's competitiveness improves with longer time budgets as the OR-Tools initialization converges. At 30\,s it surpasses the LKH-style baseline. Bold indicates best result per time limit.\relax }}{10}{table.caption.22}\protected@file@percent }
\newlabel{tab:time_budget}{{7}{10}{Optimality gap (\%) vs.\ best-known solution on 200-stop instances across time budgets. The hybrid solver's competitiveness improves with longer time budgets as the OR-Tools initialization converges. At 30\,s it surpasses the LKH-style baseline. Bold indicates best result per time limit.\relax }{table.caption.22}{}}
\newlabel{fig:solver_comparison}{{3a}{10}{Tour cost comparison across all solvers and instance scales. OR-Tools and the hybrid solver achieve the lowest costs on 200-stop instances, while the construction heuristics (NN, FI) show significantly larger gaps.\relax }{figure.caption.23}{}}
\newlabel{sub@fig:solver_comparison}{{a}{10}{Tour cost comparison across all solvers and instance scales. OR-Tools and the hybrid solver achieve the lowest costs on 200-stop instances, while the construction heuristics (NN, FI) show significantly larger gaps.\relax }{figure.caption.23}{}}
\newlabel{fig:scaling}{{3b}{10}{Computation time scaling from 50 to 2{,}000 stops. The LKH-style solver's time grows super-linearly (0.4\,s at 50 stops to 621\,s at 1{,}000), while OR-Tools and the hybrid maintain linear scaling with the time limit.\relax }{figure.caption.23}{}}
\newlabel{sub@fig:scaling}{{b}{10}{Computation time scaling from 50 to 2{,}000 stops. The LKH-style solver's time grows super-linearly (0.4\,s at 50 stops to 621\,s at 1{,}000), while OR-Tools and the hybrid maintain linear scaling with the time limit.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Benchmark results. (a)\nobreakspace  {}Solver comparison at 30\,s time limit. (b)\nobreakspace  {}Computation time scaling behavior with problem size.\relax }}{10}{figure.caption.23}\protected@file@percent }
\newlabel{fig:benchmarks}{{3}{10}{Benchmark results. (a)~Solver comparison at 30\,s time limit. (b)~Computation time scaling behavior with problem size.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.6}Scalability}{10}{subsection.6.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.7}Statistical Significance}{10}{subsection.6.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.8}Traffic Impact}{10}{subsection.6.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Discussion}{10}{section.7}\protected@file@percent }
\newlabel{sec:discussion}{{7}{10}{Discussion}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Hypothesis Evaluation}{10}{subsection.7.1}\protected@file@percent }
\citation{xin2021neurolkh}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Candidate set recall on 200-stop instances. The GNN-based candidate sets achieve higher recall than $\alpha $-nearness at small candidate set sizes ($k{=}5{,}10$), which is the regime where computational savings are largest. At $k{\geq }15$, both methods achieve perfect recall.\relax }}{11}{table.caption.24}\protected@file@percent }
\newlabel{tab:candidate_recall}{{8}{11}{Candidate set recall on 200-stop instances. The GNN-based candidate sets achieve higher recall than $\alpha $-nearness at small candidate set sizes ($k{=}5{,}10$), which is the regime where computational savings are largest. At $k{\geq }15$, both methods achieve perfect recall.\relax }{table.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Candidate set recall as a function of candidate set size $k$. The GNN-based method (blue) consistently outperforms $\alpha $-nearness (orange) at small $k$ values, achieving 94.5\% recall at $k{=}5$ vs.\ 91.5\% for $\alpha $-nearness. Both converge to 100\% at $k{\geq }15$.\relax }}{11}{figure.caption.25}\protected@file@percent }
\newlabel{fig:candidate_recall}{{4}{11}{Candidate set recall as a function of candidate set size $k$. The GNN-based method (blue) consistently outperforms $\alpha $-nearness (orange) at small $k$ values, achieving 94.5\% recall at $k{=}5$ vs.\ 91.5\% for $\alpha $-nearness. Both converge to 100\% at $k{\geq }15$.\relax }{figure.caption.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Key Insights}{11}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Initialization dominates.}{11}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Ranking vs.\ classification.}{11}{section*.32}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Time-budget sensitivity.}{11}{section*.33}\protected@file@percent }
\citation{xin2021neurolkh}
\citation{zheng2022reinforced}
\citation{wang2025mabb}
\citation{kwon2020pomo}
\citation{kool2019attention}
\citation{lischka2024great}
\citation{pan2023htsp}
\citation{perron2023ortools}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Ablation study on 200-stop instances (3 cities $\times $ 3 seeds, $T{=}10$\,s). Individual learned components (B, C) are insufficient to match the LKH-style baseline, but the full hybrid (D) with OR-Tools initialization approaches LKH-style quality. The learned candidates contribute most when combined with a strong initial tour.\relax }}{12}{table.caption.26}\protected@file@percent }
\newlabel{tab:ablation}{{9}{12}{Ablation study on 200-stop instances (3 cities $\times $ 3 seeds, $T{=}10$\,s). Individual learned components (B, C) are insufficient to match the LKH-style baseline, but the full hybrid (D) with OR-Tools initialization approaches LKH-style quality. The learned candidates contribute most when combined with a strong initial tour.\relax }{table.caption.26}{}}
\newlabel{fig:ablation}{{5a}{12}{Ablation study results. Each bar represents the mean tour cost for a configuration. The full hybrid (D) closes 88\% of the gap between the weakest component (C) and the LKH-style baseline (A).\relax }{figure.caption.27}{}}
\newlabel{sub@fig:ablation}{{a}{12}{Ablation study results. Each bar represents the mean tour cost for a configuration. The full hybrid (D) closes 88\% of the gap between the weakest component (C) and the LKH-style baseline (A).\relax }{figure.caption.27}{}}
\newlabel{fig:gap_histogram}{{5b}{12}{Distribution of optimality gaps for the hybrid solver across all 200-stop instances and seeds at $T{=}30$\,s. The majority of runs achieve gaps below 1\%, with a median of 0.05\%.\relax }{figure.caption.27}{}}
\newlabel{sub@fig:gap_histogram}{{b}{12}{Distribution of optimality gaps for the hybrid solver across all 200-stop instances and seeds at $T{=}30$\,s. The majority of runs achieve gaps below 1\%, with a median of 0.05\%.\relax }{figure.caption.27}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces (a)\nobreakspace  {}Ablation study showing contribution of each component. (b)\nobreakspace  {}Gap distribution for the hybrid solver at $T{=}30$\,s.\relax }}{12}{figure.caption.27}\protected@file@percent }
\newlabel{fig:ablation_gap}{{5}{12}{(a)~Ablation study showing contribution of each component. (b)~Gap distribution for the hybrid solver at $T{=}30$\,s.\relax }{figure.caption.27}{}}
\@writefile{toc}{\contentsline {paragraph}{Asymmetry-aware features.}{12}{section*.34}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Comparison with Prior Work}{12}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Limitations}{12}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Python implementation overhead.}{12}{section*.36}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Scalability study on Manhattan instances. The LKH-style solver's computation time grows super-linearly, reaching 621\,s at 1{,}000 stops, while OR-Tools and the hybrid maintain bounded time. At 500 stops, the hybrid achieves its smallest gap (0.25\%) due to favorable OR-Tools convergence.\relax }}{13}{table.caption.28}\protected@file@percent }
\newlabel{tab:scalability}{{10}{13}{Scalability study on Manhattan instances. The LKH-style solver's computation time grows super-linearly, reaching 621\,s at 1{,}000 stops, while OR-Tools and the hybrid maintain bounded time. At 500 stops, the hybrid achieves its smallest gap (0.25\%) due to favorable OR-Tools convergence.\relax }{table.caption.28}{}}
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Statistical significance tests (Wilcoxon signed-rank, $N{=}9$ paired comparisons). A negative mean difference indicates the hybrid is better. At $T{=}30$\,s, the hybrid is marginally better than LKH-style ($p{=}0.051$, borderline) with a medium effect size ($d{=}{-}0.78$). Small sample sizes limit statistical power.\relax }}{13}{table.caption.29}\protected@file@percent }
\newlabel{tab:statistical}{{11}{13}{Statistical significance tests (Wilcoxon signed-rank, $N{=}9$ paired comparisons). A negative mean difference indicates the hybrid is better. At $T{=}30$\,s, the hybrid is marginally better than LKH-style ($p{=}0.051$, borderline) with a medium effect size ($d{=}{-}0.78$). Small sample sizes limit statistical power.\relax }{table.caption.29}{}}
\@writefile{toc}{\contentsline {paragraph}{GNN precision.}{13}{section*.37}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Synthetic benchmarks.}{13}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Scalability.}{13}{section*.39}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{13}{section.8}\protected@file@percent }
\newlabel{sec:conclusion}{{8}{13}{Conclusion}{section.8}{}}
\citation{kool2019attention,kwon2020pomo}
\bibstyle{plainnat}
\bibdata{sources}
\bibcite{embedlkh2025}{{1}{2025}{{Anonymous}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Tour cost as a function of departure time on a 50-stop Manhattan instance. The evening peak (17:00) incurs 79.8\% higher cost than night (03:00), demonstrating that static cost models cannot capture the full complexity of real-world routing. Morning peak (08:00) incurs 44.7\% higher cost.\relax }}{14}{figure.caption.30}\protected@file@percent }
\newlabel{fig:traffic}{{6}{14}{Tour cost as a function of departure time on a 50-stop Manhattan instance. The evening peak (17:00) incurs 79.8\% higher cost than night (03:00), demonstrating that static cost models cannot capture the full complexity of real-world routing. Morning peak (08:00) incurs 44.7\% higher cost.\relax }{figure.caption.30}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Comparison with published methods. Our work is among the first to target asymmetric road-network TSP with learned components. While the absolute gap is larger than methods using the native LKH-3 C implementation, the architectural approach demonstrates that GNN-guided candidate generation transfers effectively to the directed, asymmetric setting.\relax }}{14}{table.caption.35}\protected@file@percent }
\newlabel{tab:literature}{{12}{14}{Comparison with published methods. Our work is among the first to target asymmetric road-network TSP with learned components. While the absolute gap is larger than methods using the native LKH-3 C implementation, the architectural approach demonstrates that GNN-guided candidate generation transfers effectively to the directed, asymmetric setting.\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {paragraph}{Future work.}{14}{section*.40}\protected@file@percent }
\bibcite{applegate2006traveling}{{2}{2006}{{Applegate et~al.}}{{Applegate, Bixby, Chv{\'a}tal, and Cook}}}
\bibcite{ascheuer2001solving}{{3}{2001}{{Ascheuer et~al.}}{{Ascheuer, Fischetti, and Gr{\"o}tschel}}}
\bibcite{boeing2017osmnx}{{4}{2017}{{Boeing}}{{}}}
\bibcite{cook2025korea}{{5}{2025}{{Cook et~al.}}{{Cook, Espinoza, Goycoolea, and Helsgaun}}}
\bibcite{coupey2018vroom}{{6}{2018}{{Coupey et~al.}}{{Coupey, Nicola, and Vidal}}}
\bibcite{helsgaun2000effective}{{7}{2000}{{Helsgaun}}{{}}}
\bibcite{helsgaun2009general}{{8}{2009}{{Helsgaun}}{{}}}
\bibcite{helsgaun2017extension}{{9}{2017}{{Helsgaun}}{{}}}
\bibcite{kool2019attention}{{10}{2019}{{Kool et~al.}}{{Kool, van Hoof, and Welling}}}
\bibcite{kwon2020pomo}{{11}{2020}{{Kwon et~al.}}{{Kwon, Choo, Kim, Yoon, Gwon, and Min}}}
\bibcite{lischka2024great}{{12}{2024}{{Lischka et~al.}}{{Lischka, Wu, Chehreghani, and Kulcs{\'a}r}}}
\bibcite{liu2025unics}{{13}{2025}{{Liu et~al.}}{{}}}
\bibcite{luxen2011realtime}{{14}{2011}{{Luxen and Vetter}}{{}}}
\bibcite{pan2023htsp}{{15}{2023}{{Pan et~al.}}{{Pan, Jin, Ding, Feng, Zhao, Song, and Bian}}}
\bibcite{pan2025dualopt}{{16}{2025}{{Pan et~al.}}{{Pan, Jin, Ding, Feng, Zhao, Song, and Bian}}}
\bibcite{perron2023ortools}{{17}{2023}{{Perron and Furnon}}{{}}}
\bibcite{reinelt1991tsplib}{{18}{1991}{{Reinelt}}{{}}}
\bibcite{wang2025mabb}{{19}{2025}{{Wang et~al.}}{{Wang, Zheng, Xiong, and He}}}
\bibcite{xin2021neurolkh}{{20}{2021}{{Xin et~al.}}{{Xin, Song, Cao, and Zhang}}}
\bibcite{zheng2021vsrlkh}{{21}{2021}{{Zheng et~al.}}{{Zheng, He, Zhou, Jin, and Li}}}
\bibcite{zheng2022reinforced}{{22}{2022}{{Zheng et~al.}}{{Zheng, He, Zhou, Jin, and Li}}}
\gdef \@abspage@last{16}
